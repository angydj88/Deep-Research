import time
import streamlit as st
from config import Config
from dimensions import generar_mega_prompt, crear_dimensiones
from gemini_client import GeminiClient
from report_builder import ReportBuilder

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CONFIGURACIÃ“N DE PÃGINA â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.set_page_config(
    page_title="ğŸ”¬ Deep Research Automator",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded",
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• SIDEBAR â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.title("ğŸ”¬ Deep Research")
    st.caption(f"v{Config.VERSION} Â· Powered by Gemini")
    st.divider()
    api_key = st.text_input(
        "ğŸ”‘ Gemini API Key",
        value=Config.API_KEY,
        type="password",
        help="ObtÃ©n tu key en aistudio.google.com",
    )
    if api_key:
        Config.API_KEY = api_key
    st.divider()
    with st.expander("âš™ï¸ ConfiguraciÃ³n avanzada"):
        Config.MODEL = st.selectbox(
            "Modelo",
            [
                "gemini-3-flash-preview",
                "gemini-2.0-flash",
                "gemini-2.5-flash-preview-05-20",
                "gemini-2.5-pro-preview-05-06",
            ],
            index=0,
        )
        Config.TEMPERATURE = st.slider("Temperatura", 0.0, 1.0, 0.3, 0.1)
        Config.MAX_TOKENS = st.select_slider(
            "Max tokens", [4096, 8192, 16384, 32768], value=8192
        )
        Config.DELAY_BETWEEN_CALLS = st.slider(
            "Pausa entre llamadas (s)", 1, 10, 3
        )
    st.divider()
    if st.button("ğŸ§ª Test de conexiÃ³n", use_container_width=True):
        with st.spinner("Probando..."):
            try:
                client = GeminiClient()
                resultado = client.test_conexion()
                if resultado["base"]:
                    st.success(f"âœ… ConexiÃ³n OK\n\n{resultado['detalle']}")
                else:
                    st.error(f"âŒ Fallo: {resultado['detalle']}")
            except Exception as e:
                st.error(f"âŒ Error: {e}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• CONTENIDO PRINCIPAL â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.title("ğŸ”¬ Deep Research Automator")
st.markdown("InvestigaciÃ³n exhaustiva en **7 dimensiones** usando Gemini con Google Search.")

objetivo = st.text_area(
    "ğŸ¯ Â¿QuÃ© quieres investigar?",
    placeholder="Ej: El mejor proceso en Zaragoza para blanqueamiento dental...",
    height=100,
)

st.markdown("### ğŸ“ Dimensiones a investigar")
col1, col2 = st.columns(2)
todas_dims = [
    "ğŸ“– Lenguaje y TerminologÃ­a",
    "ğŸ’° EconomÃ­a y Mercado",
    "ğŸ“Š Datos y EstadÃ­sticas",
    "ğŸ­ Sector y Competencia",
    "ğŸ¯ Estrategias y Consejos",
    "âš ï¸ Riesgos y Amenazas",
    "ğŸš€ Oportunidades y Futuro",
]
seleccionadas = []
for i, dim in enumerate(todas_dims):
    col = col1 if i < 4 else col2
    if col.checkbox(dim, value=True, key=f"dim_{i}"):
        seleccionadas.append(i)

incluir_resumen = st.checkbox("ğŸ“‹ Incluir resumen ejecutivo", value=True)
st.divider()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• EJECUTAR INVESTIGACIÃ“N â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if st.button(
    "ğŸš€ INICIAR INVESTIGACIÃ“N PROFUNDA",
    type="primary",
    use_container_width=True,
    disabled=not objetivo or not seleccionadas,
):
    errores = Config.validate()
    if errores:
        for e in errores:
            st.error(f"âŒ {e}")
        st.stop()
    if len(objetivo.strip()) < 5:
        st.error("âŒ El objetivo es demasiado corto")
        st.stop()

    client = GeminiClient()
    builder = ReportBuilder(objetivo)

    progress_bar = st.progress(0)
    status_text = st.empty()
    tiempo_inicio = time.time()

    # Generar mega-prompt primero
    progress_bar.progress(0.05)
    status_text.markdown("â³ Generando **mega-prompt optimizado**...")
    try:
        mega_base = generar_mega_prompt(client, objetivo)
    except Exception as e:
        st.error(f"âŒ Error generando mega-prompt: {e}")
        st.stop()

    dimensiones = crear_dimensiones(mega_base)
    dims_activas = [dimensiones[i] for i in seleccionadas]

    # Tabs
    tab_names = [f"{d['emoji']} {d['nombre'][:15]}" for d in dims_activas]
    if incluir_resumen:
        tab_names.append("ğŸ“‹ Resumen")
    tabs = st.tabs(tab_names)

    # Ejecutar dimensiones
    total_steps = len(dims_activas) + (1 if incluir_resumen else 0)
    for idx, dim in enumerate(dims_activas):
        progreso = (idx + 1) / total_steps
        progress_bar.progress(progreso)
        status_text.markdown(
            f"â³ **[{idx + 1}/{len(dims_activas)}]** Investigando: {dim['emoji']} {dim['nombre']}..."
        )
        with tabs[idx]:
            with st.spinner(f"Investigando {dim['nombre']}..."):
                try:
                    resultado = client.generar(dim["prompt"])
                    st.markdown(resultado["texto"])
                    if resultado["fuentes"]:
                        with st.expander("ğŸ“š Fuentes consultadas"):
                            for fuente in resultado["fuentes"]:
                                st.markdown(f"- {fuente}")
                    st.success(
                        f"âœ… {len(resultado['texto']):,} caracteres Â· MÃ©todo: {resultado['metodo']}"
                    )
                    builder.agregar_seccion(dim, resultado["texto"], resultado["fuentes"], True)
                except Exception as e:
                    st.error(f"âŒ Error: {e}")
                    builder.agregar_seccion(dim, str(e), [], False)

        if idx < len(dims_activas) - 1:
            time.sleep(Config.DELAY_BETWEEN_CALLS)

    # Resumen ejecutivo
    if incluir_resumen:
        progreso = len(dims_activas) / total_steps
        progress_bar.progress(progreso)
        status_text.markdown("â³ Generando **resumen ejecutivo**...")
        with tabs[-1]:
            with st.spinner("Sintetizando hallazgos..."):
                try:
                    extractos = "\n\n".join(
                        f"**{s['dimension']['nombre']}:**\n{s['contenido'][:1500]}..."
                        for s in builder.secciones if s["exito"]
                    )
                    prompt_resumen = (
                        f'Eres un consultor ejecutivo de Ã©lite.\n\n'
                        f'OBJETIVO: "{objetivo}"\n\n'
                        f'Extractos de 7 dimensiones:\n\n{extractos}\n\n'
                        f'GENERA UN RESUMEN EJECUTIVO con:\n'
                        f'1. CONCLUSIÃ“N PRINCIPAL\n'
                        f'2. 10 INSIGHTS MÃS IMPORTANTES\n'
                        f'3. PLAN DE ACCIÃ“N (5 pasos inmediatos)\n'
                        f'4. DECISIÃ“N CRÃTICA\n'
                        f'5. VENTAJA COMPETITIVA\n'
                        f'6. MAYOR RIESGO + mitigaciÃ³n\n'
                        f'7. OPORTUNIDAD DORADA\n'
                        f'8. PREDICCIÃ“N a 12 meses\n\n'
                        f'SÃ© directo y accionable.'
                    )
                    resp_resumen = client.generar(prompt_resumen)
                    st.markdown(resp_resumen["texto"])
                    builder.set_resumen(resp_resumen["texto"])
                    st.success("âœ… Resumen generado")
                except Exception as e:
                    st.error(f"âš ï¸ Error en resumen: {e}")

    # Finalizar
    progress_bar.progress(1.0)
    duracion = time.time() - tiempo_inicio
    stats = builder.stats
    status_text.markdown(
        f"âœ… **Â¡COMPLETADO!** Â· {stats['exitosas']}/{stats['total']} secciones "
        f"Â· {stats['caracteres']:,} caracteres "
        f"Â· {duracion / 60:.1f} minutos"
    )
    st.balloons()

    st.divider()
    st.subheader("ğŸ“¥ Descargar informe")
    rutas = builder.guardar_todo()
    col_d1, col_d2, col_d3 = st.columns(3)
    with col_d1:
        md_content = builder.exportar_markdown()
        st.download_button(
            "ğŸ“„ Descargar Markdown",
            data=md_content,
            file_name=f"informe_{objetivo[:30]}.md",
            mime="text/markdown",
            use_container_width=True,
        )
    with col_d2:
        txt_content = builder.exportar_texto_plano()
        st.download_button(
            "ğŸ“ Descargar TXT (para IA)",
            data=txt_content,
            file_name=f"informe_{objetivo[:30]}.txt",
            mime="text/plain",
            use_container_width=True,
        )
    with col_d3:
        with open(rutas["docx"], "rb") as f:
            st.download_button(
                "ğŸ“˜ Descargar Word",
                data=f.read(),
                file_name=f"informe_{objetivo[:30]}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                use_container_width=True,
            )

st.divider()
st.caption(
    f"Deep Research Automator v{Config.VERSION} Â· "
    f"Modelo: {Config.MODEL} Â· "
    f"Powered by Google Gemini"
)
